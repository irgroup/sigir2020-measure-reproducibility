{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reformat Original Runs</h1>\n",
    "<p>This script parses the original runs and:</p>\n",
    "<ol>\n",
    "<li>Keep just the assessed topics;</li>\n",
    "<li>Remove extra documents and cut the runs at 1000 documents for each topic.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import os\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "\n",
    "# Path to the folder which conteins the original runs:\n",
    "base_path = \"/Users/tjz514/Documents/uni/2020/sigir2020_reproducibility/experiments/runs/original\"\n",
    "# Path to the folder which contains the assessed topics\n",
    "qrels_file = \"/Users/tjz514/Documents/uni/2020/sigir2020_reproducibility/experiments/qrels/qrels_common_core_2017.txt\"\n",
    "# run name\n",
    "run_name = \"WCrobust0405\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ids of the assessed topics\n",
    "\n",
    "# We will get them from the qrels file instead of parsing the topic file\n",
    "# The fields in the qrels file are space separated\n",
    "# Initialize the set which will store the topic id\n",
    "assessed_topic_ids = set()\n",
    "\n",
    "# read the input file as a whole\n",
    "with open(qrels_file) as f:\n",
    "    input_file = f.readlines()\n",
    "\n",
    "# parse each line and populate the corresponding dictionaries\n",
    "for line in input_file:\n",
    "    # parse the line and keep only the topic_id  \n",
    "    topic_id, _, _, _ = line.strip().split()\n",
    "    \n",
    "    # Add the topic id to the set of topic ids\n",
    "    assessed_topic_ids.add(int(topic_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the original run\n",
    "\n",
    "# Path to the original run\n",
    "run_file = os.path.join(base_path, (run_name + \".txt\"))\n",
    "\n",
    "# Initialize the run as a list of tuples\n",
    "# (topic_id, doc_id, rank, score)\n",
    "run = []\n",
    "\n",
    "# Read the input file as a whole\n",
    "with open(run_file) as f:\n",
    "    input_file = f.readlines()\n",
    "\n",
    "# Parse each line and populate the corresponding dictionaries\n",
    "for line in input_file:\n",
    "    # parse the line and keep only the topic_id  \n",
    "    topic_id, _, doc_id, rank, score, _ = line.strip().split()\n",
    "    # Add the tuple to the list\n",
    "    run.append((int(topic_id), doc_id, int(rank), score))\n",
    "\n",
    "# Close the run file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the run by topic id and rank\n",
    "run.sort(key=itemgetter(2))         # rank ascending\n",
    "run.sort(key=itemgetter(0))         # topic_id ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the new run: keep only the assessed topics and 1000 documents for each topic\n",
    "\n",
    "# Path to the new run file\n",
    "new_run_file = os.path.join(base_path, (run_name + \"_replicability.txt\"))\n",
    "# Open a new file to write the run\n",
    "new_run_f = open(new_run_file, \"w+\")\n",
    "# Initialize the topic_id\n",
    "current_topic_id = \"\"\n",
    "# Maximum number of documents for each topic\n",
    "max_rank = 1000\n",
    "\n",
    "# For each item in the run list\n",
    "for (topic_id, doc_id, rank, score) in run:\n",
    "    # Check if the topic is in the set of assessed topics\n",
    "    if topic_id in assessed_topic_ids:\n",
    "    \n",
    "        # Check if the topic_id has changed\n",
    "        if current_topic_id != topic_id:\n",
    "            # Update the current topic_id\n",
    "            current_topic_id = topic_id\n",
    "            # Update the rank position\n",
    "            current_rank = 0\n",
    "\n",
    "        # If the rank is lower than the maximum allowed\n",
    "        if current_rank < max_rank:\n",
    "            # Write the data in the new run file\n",
    "            string_results = \"%i\\tQ0\\t%s\\t%i\\t%s\\t%s\\n\" % (topic_id, doc_id, rank, score, run_name)\n",
    "            # print(string_results)\n",
    "            new_run_f.write(string_results)\n",
    "\n",
    "        # Update the current rank\n",
    "        current_rank = current_rank + 1\n",
    "\n",
    "# Close the new run file\n",
    "new_run_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
